{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d79ec726",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "warnings.simplefilter(\"ignore\", FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1e70e90d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6919233c",
      "metadata": {},
      "source": [
        "# First Read the SITS Data\n",
        "\n",
        "sktime requires 3d numpy arrays of the form\n",
        "\n",
        "$$(#ts, #channels, #time stamps)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "022894a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 1, 138)\n"
          ]
        }
      ],
      "source": [
        "# you can use a larger subset, if you like, there are:\n",
        "# - SITS-train-phase2-subset-1000000.csv.gz\n",
        "# - SITS-train-phase2-subset-100000.csv.gz\n",
        "# - SITS-train-phase2-subset-10000.csv.gz\n",
        "DATA_TRAIN = \"./dataset/SITS-train-phase2-subset-10000.csv.gz\"\n",
        "\n",
        "# Set univariate=True, if you use a classifier with multivariate capabilities\n",
        "def read_data_sktime(DATA, univariate=False):\n",
        "    data = pd.read_csv(DATA, delimiter=\",\" , \n",
        "                       na_values=['?'], dtype='float', \n",
        "                       index_col=\"id\", compression='gzip')\n",
        "\n",
        "    # Fill NaN values\n",
        "    # We use the most basic way with bfill and ffill to carry on the last values\n",
        "    data.fillna(method='bfill', inplace=True, axis=1)\n",
        "    data.fillna(method='ffill', inplace=True, axis=1)\n",
        "\n",
        "    # Extract Data and Labels\n",
        "    X = data.iloc[:,1:].values\n",
        "    y = data.iloc[:,0].astype(int)\n",
        "\n",
        "\n",
        "    if univariate:\n",
        "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "    else:\n",
        "        X = X.reshape(X.shape[0], 3, X.shape[1]//3)\n",
        "        \n",
        "        \n",
        "    print(X.shape)\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = read_data_sktime(DATA_TRAIN, univariate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51974406",
      "metadata": {},
      "source": [
        "# Train a sklearn Random Forest Model \n",
        "\n",
        "We are using GridSearch and Cross-Validation to train the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "417613b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "Best F1-Score: 0.6770186730719441\n",
            "Time taken: 384.10061\n",
            "Detailed scores on train dataset:\n",
            "\n",
            "0.676 (+/-0.007) for \n",
            "\t {'n_estimators': 100, 'n_jobs': -1, 'random_state': 1}\n",
            "\n",
            "0.677 (+/-0.014) for \n",
            "\t {'n_estimators': 200, 'n_jobs': -1, 'random_state': 1}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "                \"n_estimators\": [100, 200],\n",
        "                \"random_state\": [1],\n",
        "                \"n_jobs\":[-1],\n",
        "              }\n",
        "\n",
        "# choose a classifier\n",
        "clf = TimeSeriesForestClassifier()\n",
        "scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "# perform a grid-search\n",
        "fit_time = time.perf_counter()\n",
        "grid = GridSearchCV(clf, param_grid, cv = 5, scoring=scorer, refit=True, n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train, y_train)\n",
        "fit_time = np.round(time.perf_counter() - fit_time, 5)\n",
        "\n",
        "# get best model\n",
        "best_clf = grid.best_estimator_\n",
        "best_params = grid.best_params_\n",
        "best_score = grid.best_score_\n",
        "\n",
        "print(\"Best F1-Score:\", best_score)\n",
        "print(\"Time taken:\", fit_time)\n",
        "\n",
        "print(\"Detailed scores on train dataset:\")\n",
        "print()\n",
        "means = grid.cv_results_['mean_test_score']\n",
        "stds = grid.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for \\n\\t %r\"% (mean, std * 2, params))\n",
        "    print()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e8d938",
      "metadata": {},
      "source": [
        "# Submit your solution to Kaggle\n",
        "\n",
        "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
        "Create a submission named `submission.csv` using your model and upload it to kaggle:\n",
        "\n",
        "- Phase 1: https://www.kaggle.com/competitions/sits-ws22-phase1\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf90d4a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the data\n",
        "DATA_TEST = \"../dataset/phase2/SITS-test-data-phase2-nolabel.csv.gz\"\n",
        "\n",
        "X_test, _ = read_data_sktime(DATA_TEST, univariate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696cf101",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a prediction\n",
        "predictions = best_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f918ccc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a submission file for kaggle\n",
        "submission = pd.DataFrame({'PREDICTED': predictions})\n",
        "submission.index.name=\"ID\"\n",
        "\n",
        "filename = 'baseline_tsf_submission_phase2.csv'\n",
        "submission.to_csv(filename,index=True)\n",
        "print('Saved file: ' + filename)\n",
        "\n",
        "#Visualize the first 5 rows\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e21e4fff",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "se-algo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "d60c5db3aec7d16228bab3ba3eec9f93f4bf56b1ba85fb182ac2c432355efff5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
