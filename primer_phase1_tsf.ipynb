{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79ec726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Only print warnings, ignore info and error \n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6919233c",
   "metadata": {},
   "source": [
    "# First Read the SITS Data\n",
    "\n",
    "sktime requires 3d numpy arrays of the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022894a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 138)\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN = \"./dataset/SITS-train-phase1-subset-1000.csv\"\n",
    "\n",
    "\n",
    "# Set univariate=True, if you use a classifier with multivariate capabilities\n",
    "def read_data_sktime(DATA, univariate=False):\n",
    "    data = pd.read_csv(DATA, delimiter=\",\" , na_values=['?'], dtype='float', index_col=\"id\")\n",
    "\n",
    "    # Extract Data and Labels\n",
    "    X = data.iloc[:,1:].values\n",
    "    y = data.iloc[:,0].astype(int)\n",
    "\n",
    "    if univariate:\n",
    "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    else:\n",
    "        X = X.reshape(X.shape[0], 3, X.shape[1]//3)\n",
    "        \n",
    "        \n",
    "    print(X.shape)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = read_data_sktime(DATA_TRAIN, univariate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51974406",
   "metadata": {},
   "source": [
    "# Train a sklearn Random Forest Model \n",
    "\n",
    "We are using GridSearch and Cross-Validation to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417613b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best F1-Score: 0.5976525388868892\n",
      "Time taken: 8.15445\n",
      "Detailed scores on train dataset:\n",
      "\n",
      "0.582 (+/-0.060) for \n",
      "\t {'n_estimators': 100, 'n_jobs': -1, 'random_state': 1}\n",
      "\n",
      "0.598 (+/-0.076) for \n",
      "\t {'n_estimators': 200, 'n_jobs': -1, 'random_state': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"n_estimators\": [100, 200],\n",
    "                \"random_state\": [1],\n",
    "                \"n_jobs\":[-1],\n",
    "              }\n",
    "\n",
    "# choose a classifier\n",
    "clf = TimeSeriesForestClassifier()\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# perform a grid-search\n",
    "fit_time = time.perf_counter()\n",
    "grid = GridSearchCV(clf, param_grid, cv = 5, scoring=scorer, refit=True, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "fit_time = np.round(time.perf_counter() - fit_time, 5)\n",
    "\n",
    "# get best model\n",
    "best_clf = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "\n",
    "print(\"Best F1-Score:\", best_score)\n",
    "print(\"Time taken:\", fit_time)\n",
    "\n",
    "print(\"Detailed scores on train dataset:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for \\n\\t %r\"% (mean, std * 2, params))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8d938",
   "metadata": {},
   "source": [
    "# Submit your solution to Kaggle\n",
    "\n",
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "Create a submission named `submission.csv` using your model and upload it to kaggle:\n",
    "\n",
    "- Phase 1: TODO\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf90d4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1, 138)\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "DATA_TEST = \"./dataset/SITS-test-data-phase1-nolabel.csv\"\n",
    "\n",
    "X_test, _ = read_data_sktime(DATA_TEST, univariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696cf101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "predictions = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f918ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: baseline_tsf_submission_phase1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTED</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PREDICTED\n",
       "ID           \n",
       "0           1\n",
       "1           6\n",
       "2           9\n",
       "3          18\n",
       "4           3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a submission file for kaggle\n",
    "submission = pd.DataFrame({'PREDICTED': predictions})\n",
    "submission.index.name=\"ID\"\n",
    "\n",
    "filename = 'baseline_tsf_submission_phase1.csv'\n",
    "submission.to_csv(filename,index=True)\n",
    "print('Saved file: ' + filename)\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d3184",
   "metadata": {},
   "source": [
    "# Try again with Deep Learning CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218d10e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 138)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.pyenv/versions/3.7.5/envs/se-algo-timeseries/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "2022-11-06 13:06:43.041399: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-06 13:06:43.044265: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-06 13:06:43.068076: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-06 13:06:43.068575: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-06 13:06:43.080820: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 939us/step\n",
      "13/13 [==============================] - 0s 859us/step\n",
      "13/13 [==============================] - 0s 663us/step\n",
      "13/13 [==============================] - 0s 705us/step\n",
      "Best F1-Score: 0.5195263476624876\n",
      "Time taken: 347.59891\n",
      "Detailed scores on train dataset:\n",
      "\n",
      "0.520 (+/-0.037) for \n",
      "\t {'kernel_size': 7, 'n_conv_layers': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Only print warnings, ignore info and error \n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "\n",
    "from sktime.classification.deep_learning import CNNClassifier\n",
    "\n",
    "DATA_TRAIN = \"./dataset/SITS-train-phase1-subset-1000.csv\"\n",
    "\n",
    "\n",
    "# Set univariate=True, if you use a classifier with multivariate capabilities\n",
    "def read_data_sktime(DATA, univariate=False):\n",
    "    data = pd.read_csv(DATA, delimiter=\",\" , na_values=['?'], dtype='float', index_col=\"id\")\n",
    "\n",
    "    # Extract Data and Labels\n",
    "    X = data.iloc[:,1:].values\n",
    "    y = data.iloc[:,0].astype(int)\n",
    "\n",
    "    if univariate:\n",
    "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    else:\n",
    "        X = X.reshape(X.shape[0], 3, X.shape[1]//3)\n",
    "        \n",
    "        \n",
    "    print(X.shape)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = read_data_sktime(DATA_TRAIN, univariate=True)\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#                 \"kernel_size\": [3,5,7,9,11],\n",
    "#                 \"n_conv_layers\": [2,3,5,7],\n",
    "#               }\n",
    "\n",
    "param_grid = {\n",
    "                \"kernel_size\": [7],\n",
    "                \"n_conv_layers\": [2],\n",
    "              }\n",
    "\n",
    "# choose a classifier\n",
    "clf = CNNClassifier()\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# perform a grid-search\n",
    "fit_time = time.perf_counter()\n",
    "grid = GridSearchCV(clf, param_grid, cv = 5, scoring=scorer, refit=True, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "fit_time = np.round(time.perf_counter() - fit_time, 5)\n",
    "\n",
    "# get best model\n",
    "best_clf = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "\n",
    "print(\"Best F1-Score:\", best_score)\n",
    "print(\"Time taken:\", fit_time)\n",
    "\n",
    "print(\"Detailed scores on train dataset:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for \\n\\t %r\"% (mean, std * 2, params))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1ccc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e229c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['activation', 'avg_pool_size', 'batch_size', 'callbacks', 'kernel_size', 'loss', 'metrics', 'n_conv_layers', 'n_epochs', 'optimizer', 'random_state', 'use_bias', 'verbose'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params().keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('se-algo-timeseries')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c5b454c6344d901b60c31445b6f796b4db34a2188a0e869ba4b24428762ebb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
