{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef176be",
   "metadata": {},
   "source": [
    "# Train sktime-dl LSTM-FCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4365e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\nicol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sktime\\utils\\validation\\_dependencies.py:117: UserWarning: No module named 'keras_self_attention'. 'keras-self-attention' is a soft dependency and not included in the base sktime installation. Please run: `pip install keras-self-attention` to install the keras-self-attention package. To install all soft dependencies, run: `pip install sktime[all_extras]`\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Only print warnings, ignore info and error \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # Disable GPU\n",
    "\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' \n",
    "# import tensorflow as tf\n",
    "# tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from sktime.classification.deep_learning.mlstmfcn import MLSTMFCNClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf079b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 3, 46)\n",
      "Training data:\n",
      "(950000, 3, 46)\n",
      "(950000,)\n",
      "\n",
      "Validation data:\n",
      "(50000, 3, 46)\n",
      "(50000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can use a larger subset, if you like, there are:\n",
    "# - SITS-train-phase2-subset-1000000.csv.gz\n",
    "# - SITS-train-phase2-subset-100000.csv.gz\n",
    "# - SITS-train-phase2-subset-10000.csv.gz\n",
    "DATA_TRAIN = \"./dataset/SITS-train-phase2-subset-1000000.csv.gz\"\n",
    "use_univariate = False\n",
    "\n",
    "# Set univariate=False, if you use a classifier with multivariate capabilities\n",
    "def read_data_sktime(DATA, univariate=False):\n",
    "    data = pd.read_csv(DATA, delimiter=\",\" , \n",
    "                       na_values=['?'], dtype='float', \n",
    "                       index_col=\"id\", compression='gzip')\n",
    "\n",
    "    # Fill NaN values\n",
    "    # We use the most basic way with bfill and ffill to carry on the last values\n",
    "    data.fillna(method='bfill', inplace=True, axis=1)\n",
    "    data.fillna(method='ffill', inplace=True, axis=1)\n",
    "\n",
    "    # Extract Data and Labels\n",
    "    X = np.array(data.iloc[:,1:].values)\n",
    "    y = np.array(data.iloc[:,0].astype(int))\n",
    "\n",
    "\n",
    "    if univariate:\n",
    "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    else:\n",
    "        X = X.reshape(X.shape[0], 3, X.shape[1]//3)\n",
    "        \n",
    "        \n",
    "    print(X.shape)\n",
    "    return X, y\n",
    "\n",
    "X, y = read_data_sktime(DATA_TRAIN, univariate=use_univariate)\n",
    "\n",
    "for (train_ix, test_ix)  in StratifiedShuffleSplit(n_splits=1, test_size=0.05, random_state=42).split(X, y):\n",
    "    X_train, y_train = X[train_ix], y[train_ix]\n",
    "    X_val, y_val = X[test_ix], y[test_ix]\n",
    "\n",
    "\n",
    "    print(\"Training data:\")\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print()\n",
    "\n",
    "    print(\"Validation data:\")\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b861481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.7, patience=10, min_lr=0.0001)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "tensorboard = callbacks.TensorBoard(log_dir=\"./tensorboard/phase_2_mlstm_full_dataset_tuned_and_fixed_multivariate_with_dilation\", histogram_freq=1)\n",
    "# model_save = callbacks.ModelCheckpoint('best_model_exploring.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "callbacks_ = [early_stopping, reduce_lr, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf156fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLSTMFCNWithValidation(MLSTMFCNClassifier):\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None, use_dimension_shuffle = True,  **kwargs):\n",
    "        self.reset()\n",
    "\n",
    "        start = int(round(time.time() * 1000))\n",
    "        # convenience conversions to allow user flexibility:\n",
    "        # if X is 2D array, convert to 3D, if y is Series, convert to numpy\n",
    "        X, y = self._internal_convert(X, y)\n",
    "        X_metadata = self._check_classifier_input(X, y)\n",
    "        missing = X_metadata[\"has_nans\"]\n",
    "        multivariate = not X_metadata[\"is_univariate\"]\n",
    "        unequal = not X_metadata[\"is_equal_length\"]\n",
    "        self._X_metadata = X_metadata\n",
    "\n",
    "        # Check this classifier can handle characteristics\n",
    "        self._check_capabilities(missing, multivariate, unequal)\n",
    "\n",
    "        # remember class labels\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = self.classes_.shape[0]\n",
    "        self._class_dictionary = {}\n",
    "        for index, class_val in enumerate(self.classes_):\n",
    "            self._class_dictionary[class_val] = index\n",
    "\n",
    "        # escape early and do not fit if only one class label has been seen\n",
    "        #   in this case, we later predict the single class label seen\n",
    "        if len(self.classes_) == 1:\n",
    "            self.fit_time_ = int(round(time.time() * 1000)) - start\n",
    "            self._is_fitted = True\n",
    "            return self\n",
    "\n",
    "        # Convert data as dictated by the classifier tags\n",
    "        X = self._convert_X(X)\n",
    "        multithread = self.get_tag(\"capability:multithreading\")\n",
    "        if multithread:\n",
    "            try:\n",
    "                self._threads_to_use = check_n_jobs(self.n_jobs)\n",
    "            except NameError:\n",
    "                raise AttributeError(\n",
    "                    \"self.n_jobs must be set if capability:multithreading is True\"\n",
    "                )\n",
    "\n",
    "        # pass coerced and checked data to inner _fit\n",
    "        self._fit(X, y, X_val, y_val, use_dimension_shuffle, **kwargs)\n",
    "        self.fit_time_ = int(round(time.time() * 1000)) - start\n",
    "\n",
    "        # this should happen last\n",
    "        self._is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def _fit(self, X, y, X_val=None, y_val=None, use_dimension_shuffle=True, **kwargs):\n",
    "        from sklearn.utils.validation import check_random_state\n",
    "        \n",
    "        self.random_state = check_random_state(self.random_state)\n",
    "        y_onehot = self.convert_y_to_keras(y)\n",
    "        \n",
    "        if y_val is not None:\n",
    "            y_val = self.label_encoder.transform(y_val)\n",
    "            y_val = y_val.reshape(-1, 1)\n",
    "            y_val = self.onehot_encoder.transform(y_val)\n",
    "\n",
    "        if use_dimension_shuffle:\n",
    "            #Transpose to conform to Keras input style.\n",
    "            X = X.transpose(0, 2, 1)\n",
    "            \n",
    "            if X_val is not None:\n",
    "                X_val = X_val.transpose(0, 2, 1)\n",
    "             \n",
    "        validation_data = (X_val, y_val) if X_val is not None and y_val is not None else None\n",
    "\n",
    "        # ignore the number of instances, X.shape[0],\n",
    "        # just want the shape of each instance\n",
    "        self.input_shape = X.shape[1:]\n",
    "\n",
    "        self.model_ = self.build_model(self.input_shape, self.n_classes_)\n",
    "\n",
    "        if self.verbose:\n",
    "            self.model_.summary()\n",
    "\n",
    "        self.history = self.model_.fit(\n",
    "            X,\n",
    "            y_onehot,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.n_epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_data=validation_data,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self._is_fitted = True\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, use_dimension_shuffle=True) -> np.ndarray:\n",
    "        self.check_is_fitted()\n",
    "\n",
    "        # boilerplate input checks for predict-like methods\n",
    "        X = self._check_convert_X_for_predict(X)\n",
    "\n",
    "        # handle the single-class-label case\n",
    "        if len(self._class_dictionary) == 1:\n",
    "            return self._single_class_y_pred(X, method=\"predict\")\n",
    "\n",
    "        # call internal _predict_proba\n",
    "        return self._predict(X, use_dimension_shuffle)\n",
    "    \n",
    "    def _predict(self, X, use_dimension_shuffle=True, **kwargs):\n",
    "        probs = self._predict_proba(X, use_dimension_shuffle=True, **kwargs)\n",
    "        \n",
    "        from sklearn.utils import check_random_state\n",
    "        rng = check_random_state(self.random_state)\n",
    "        return np.array(\n",
    "            [\n",
    "                self.classes_[int(rng.choice(np.flatnonzero(prob == prob.max())))]\n",
    "                for prob in probs\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _predict_proba(self, X, use_dimension_shuffle=True, **kwargs):\n",
    "        \n",
    "        if use_dimension_shuffle:\n",
    "            # Transpose to work correctly with keras\n",
    "            X = X.transpose((0, 2, 1))\n",
    "        \n",
    "        probs = self.model_.predict(X, self.batch_size, **kwargs)\n",
    "\n",
    "        # check if binary classification\n",
    "        if probs.shape[1] == 1:\n",
    "            # first column is probability of class 0 and second is of class 1\n",
    "            probs = np.hstack([1 - probs, probs])\n",
    "        probs = probs / probs.sum(axis=1, keepdims=1)\n",
    "        return probs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c96bbf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 3, 950000)\n",
      "(950000,)\n",
      "(46, 3, 50000)\n",
      "(50000,)\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)          [(None, 3, 46)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_75 (Conv1D)             (None, 3, 128)       47232       ['input_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 3, 128)      512         ['conv1d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 3, 128)       0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_75 (G  (None, 128)         0           ['activation_75[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " reshape_50 (Reshape)           (None, 1, 128)       0           ['global_average_pooling1d_75[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_125 (Dense)              (None, 1, 8)         1024        ['reshape_50[0][0]']             \n",
      "                                                                                                  \n",
      " dense_126 (Dense)              (None, 1, 128)       1024        ['dense_125[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_50 (Multiply)         (None, 3, 128)       0           ['activation_75[0][0]',          \n",
      "                                                                  'dense_126[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_76 (Conv1D)             (None, 3, 256)       164096      ['multiply_50[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 3, 256)      1024        ['conv1d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 3, 256)       0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_76 (G  (None, 256)         0           ['activation_76[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " reshape_51 (Reshape)           (None, 1, 256)       0           ['global_average_pooling1d_76[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_127 (Dense)              (None, 1, 16)        4096        ['reshape_51[0][0]']             \n",
      "                                                                                                  \n",
      " dense_128 (Dense)              (None, 1, 256)       4096        ['dense_127[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_51 (Multiply)         (None, 3, 256)       0           ['activation_76[0][0]',          \n",
      "                                                                  'dense_128[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_77 (Conv1D)             (None, 3, 128)       98432       ['multiply_51[0][0]']            \n",
      "                                                                                                  \n",
      " permute_25 (Permute)           (None, 46, 3)        0           ['input_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 3, 128)      512         ['conv1d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_25 (LSTM)                 (None, 8)            384         ['permute_25[0][0]']             \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 3, 128)       0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 8)            0           ['lstm_25[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_77 (G  (None, 128)         0           ['activation_77[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 136)          0           ['dropout_25[0][0]',             \n",
      "                                                                  'global_average_pooling1d_77[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_129 (Dense)              (None, 24)           3288        ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 325,720\n",
      "Trainable params: 324,696\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "29688/29688 [==============================] - 422s 14ms/step - loss: 0.7815 - accuracy: 0.7252 - val_loss: 0.7583 - val_accuracy: 0.7300 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "29688/29688 [==============================] - 425s 14ms/step - loss: 0.6642 - accuracy: 0.7664 - val_loss: 0.6463 - val_accuracy: 0.7715 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "29688/29688 [==============================] - 453s 15ms/step - loss: 0.6191 - accuracy: 0.7816 - val_loss: 0.6156 - val_accuracy: 0.7834 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "29688/29688 [==============================] - 415s 14ms/step - loss: 0.5914 - accuracy: 0.7920 - val_loss: 0.6120 - val_accuracy: 0.7837 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "29688/29688 [==============================] - 414s 14ms/step - loss: 0.5709 - accuracy: 0.7990 - val_loss: 0.5864 - val_accuracy: 0.7922 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "29688/29688 [==============================] - 412s 14ms/step - loss: 0.5544 - accuracy: 0.8047 - val_loss: 0.5631 - val_accuracy: 0.8012 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "29688/29688 [==============================] - 412s 14ms/step - loss: 0.5415 - accuracy: 0.8089 - val_loss: 0.5561 - val_accuracy: 0.8042 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "29688/29688 [==============================] - 411s 14ms/step - loss: 0.5294 - accuracy: 0.8135 - val_loss: 0.5362 - val_accuracy: 0.8114 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "29688/29688 [==============================] - 401s 14ms/step - loss: 0.5197 - accuracy: 0.8165 - val_loss: 0.5491 - val_accuracy: 0.8077 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "29688/29688 [==============================] - 354s 12ms/step - loss: 0.5109 - accuracy: 0.8197 - val_loss: 0.5690 - val_accuracy: 0.7998 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "29688/29688 [==============================] - 339s 11ms/step - loss: 0.5025 - accuracy: 0.8221 - val_loss: 0.5313 - val_accuracy: 0.8150 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "29688/29688 [==============================] - 341s 11ms/step - loss: 0.4959 - accuracy: 0.8245 - val_loss: 0.5341 - val_accuracy: 0.8128 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "29688/29688 [==============================] - 401s 14ms/step - loss: 0.4891 - accuracy: 0.8267 - val_loss: 0.5111 - val_accuracy: 0.8208 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "29688/29688 [==============================] - 401s 14ms/step - loss: 0.4831 - accuracy: 0.8290 - val_loss: 0.5019 - val_accuracy: 0.8255 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "29688/29688 [==============================] - 403s 14ms/step - loss: 0.4781 - accuracy: 0.8305 - val_loss: 0.5100 - val_accuracy: 0.8218 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "29688/29688 [==============================] - 401s 13ms/step - loss: 0.4727 - accuracy: 0.8324 - val_loss: 0.5088 - val_accuracy: 0.8205 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "29688/29688 [==============================] - 402s 14ms/step - loss: 0.4680 - accuracy: 0.8338 - val_loss: 0.4924 - val_accuracy: 0.8286 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "29688/29688 [==============================] - 398s 13ms/step - loss: 0.4642 - accuracy: 0.8349 - val_loss: 0.5183 - val_accuracy: 0.8166 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "29688/29688 [==============================] - 406s 14ms/step - loss: 0.4593 - accuracy: 0.8369 - val_loss: 0.4992 - val_accuracy: 0.8260 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "29688/29688 [==============================] - 401s 14ms/step - loss: 0.4550 - accuracy: 0.8383 - val_loss: 0.5003 - val_accuracy: 0.8260 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "29688/29688 [==============================] - 403s 14ms/step - loss: 0.4519 - accuracy: 0.8392 - val_loss: 0.4860 - val_accuracy: 0.8308 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "29688/29688 [==============================] - 400s 13ms/step - loss: 0.4482 - accuracy: 0.8405 - val_loss: 0.4902 - val_accuracy: 0.8297 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "29688/29688 [==============================] - 401s 14ms/step - loss: 0.4443 - accuracy: 0.8421 - val_loss: 0.4849 - val_accuracy: 0.8324 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "29688/29688 [==============================] - 406s 14ms/step - loss: 0.4413 - accuracy: 0.8431 - val_loss: 0.4930 - val_accuracy: 0.8296 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "29688/29688 [==============================] - 400s 13ms/step - loss: 0.4384 - accuracy: 0.8439 - val_loss: 0.4926 - val_accuracy: 0.8309 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "29688/29688 [==============================] - 400s 13ms/step - loss: 0.4354 - accuracy: 0.8448 - val_loss: 0.4829 - val_accuracy: 0.8303 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "29688/29688 [==============================] - 399s 13ms/step - loss: 0.4326 - accuracy: 0.8455 - val_loss: 0.4871 - val_accuracy: 0.8299 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "29688/29688 [==============================] - 414s 14ms/step - loss: 0.4303 - accuracy: 0.8464 - val_loss: 0.4686 - val_accuracy: 0.8383 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "29688/29688 [==============================] - 400s 13ms/step - loss: 0.4271 - accuracy: 0.8475 - val_loss: 0.4832 - val_accuracy: 0.8324 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "29688/29688 [==============================] - 405s 14ms/step - loss: 0.4244 - accuracy: 0.8485 - val_loss: 0.4873 - val_accuracy: 0.8301 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "29688/29688 [==============================] - 402s 14ms/step - loss: 0.4221 - accuracy: 0.8493 - val_loss: 0.4878 - val_accuracy: 0.8345 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "29688/29688 [==============================] - 408s 14ms/step - loss: 0.4195 - accuracy: 0.8500 - val_loss: 0.4801 - val_accuracy: 0.8327 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "29688/29688 [==============================] - 403s 14ms/step - loss: 0.4174 - accuracy: 0.8509 - val_loss: 0.4705 - val_accuracy: 0.8365 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "29688/29688 [==============================] - 402s 14ms/step - loss: 0.4157 - accuracy: 0.8516 - val_loss: 0.4838 - val_accuracy: 0.8340 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "29688/29688 [==============================] - 405s 14ms/step - loss: 0.4135 - accuracy: 0.8524 - val_loss: 0.4753 - val_accuracy: 0.8360 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "29688/29688 [==============================] - 402s 14ms/step - loss: 0.4113 - accuracy: 0.8528 - val_loss: 0.4809 - val_accuracy: 0.8348 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "29688/29688 [==============================] - 410s 14ms/step - loss: 0.4097 - accuracy: 0.8533 - val_loss: 0.4777 - val_accuracy: 0.8342 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "29688/29688 [==============================] - 403s 14ms/step - loss: 0.4076 - accuracy: 0.8540 - val_loss: 0.4722 - val_accuracy: 0.8359 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "29688/29688 [==============================] - 401s 14ms/step - loss: 0.4060 - accuracy: 0.8547 - val_loss: 0.4749 - val_accuracy: 0.8361 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "29688/29688 [==============================] - 403s 14ms/step - loss: 0.4040 - accuracy: 0.8555 - val_loss: 0.4674 - val_accuracy: 0.8391 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "29688/29688 [==============================] - 407s 14ms/step - loss: 0.4022 - accuracy: 0.8558 - val_loss: 0.4619 - val_accuracy: 0.8405 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "29688/29688 [==============================] - 406s 14ms/step - loss: 0.4006 - accuracy: 0.8565 - val_loss: 0.4757 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "29688/29688 [==============================] - 403s 14ms/step - loss: 0.3992 - accuracy: 0.8572 - val_loss: 0.4715 - val_accuracy: 0.8388 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "29688/29688 [==============================] - 399s 13ms/step - loss: 0.3973 - accuracy: 0.8576 - val_loss: 0.4783 - val_accuracy: 0.8361 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "29688/29688 [==============================] - 395s 13ms/step - loss: 0.3953 - accuracy: 0.8579 - val_loss: 0.4758 - val_accuracy: 0.8372 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "29688/29688 [==============================] - 396s 13ms/step - loss: 0.3942 - accuracy: 0.8586 - val_loss: 0.4717 - val_accuracy: 0.8372 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "29688/29688 [==============================] - 387s 13ms/step - loss: 0.3932 - accuracy: 0.8590 - val_loss: 0.4650 - val_accuracy: 0.8402 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "29688/29688 [==============================] - 391s 13ms/step - loss: 0.3915 - accuracy: 0.8596 - val_loss: 0.4724 - val_accuracy: 0.8405 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "29688/29688 [==============================] - 393s 13ms/step - loss: 0.3897 - accuracy: 0.8603 - val_loss: 0.4684 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "29688/29688 [==============================] - 403s 14ms/step - loss: 0.3885 - accuracy: 0.8605 - val_loss: 0.4789 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "29688/29688 [==============================] - 393s 13ms/step - loss: 0.3875 - accuracy: 0.8610 - val_loss: 0.4626 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "29688/29688 [==============================] - 392s 13ms/step - loss: 0.3858 - accuracy: 0.8615 - val_loss: 0.4547 - val_accuracy: 0.8435 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "29688/29688 [==============================] - 391s 13ms/step - loss: 0.3845 - accuracy: 0.8619 - val_loss: 0.4651 - val_accuracy: 0.8405 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "29688/29688 [==============================] - 398s 13ms/step - loss: 0.3831 - accuracy: 0.8621 - val_loss: 0.4677 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "29688/29688 [==============================] - 400s 13ms/step - loss: 0.3821 - accuracy: 0.8627 - val_loss: 0.4649 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "29688/29688 [==============================] - 387s 13ms/step - loss: 0.3811 - accuracy: 0.8629 - val_loss: 0.4649 - val_accuracy: 0.8423 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "29688/29688 [==============================] - 393s 13ms/step - loss: 0.3803 - accuracy: 0.8633 - val_loss: 0.4774 - val_accuracy: 0.8399 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "29688/29688 [==============================] - 388s 13ms/step - loss: 0.3784 - accuracy: 0.8638 - val_loss: 0.4758 - val_accuracy: 0.8377 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "29688/29688 [==============================] - 392s 13ms/step - loss: 0.3784 - accuracy: 0.8638 - val_loss: 0.4813 - val_accuracy: 0.8361 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "29688/29688 [==============================] - 397s 13ms/step - loss: 0.3766 - accuracy: 0.8644 - val_loss: 0.4621 - val_accuracy: 0.8434 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "29688/29688 [==============================] - 391s 13ms/step - loss: 0.3750 - accuracy: 0.8651 - val_loss: 0.4605 - val_accuracy: 0.8431 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "29688/29688 [==============================] - 391s 13ms/step - loss: 0.3743 - accuracy: 0.8652 - val_loss: 0.4617 - val_accuracy: 0.8448 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "29688/29688 [==============================] - 391s 13ms/step - loss: 0.3734 - accuracy: 0.8657 - val_loss: 0.4687 - val_accuracy: 0.8398 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "29688/29688 [==============================] - 393s 13ms/step - loss: 0.3727 - accuracy: 0.8658 - val_loss: 0.4625 - val_accuracy: 0.8448 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "29688/29688 [==============================] - 395s 13ms/step - loss: 0.3710 - accuracy: 0.8662 - val_loss: 0.4617 - val_accuracy: 0.8429 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "29688/29688 [==============================] - 394s 13ms/step - loss: 0.3696 - accuracy: 0.8670 - val_loss: 0.4687 - val_accuracy: 0.8414 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "29688/29688 [==============================] - 392s 13ms/step - loss: 0.3698 - accuracy: 0.8669 - val_loss: 0.4669 - val_accuracy: 0.8441 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "29688/29688 [==============================] - 397s 13ms/step - loss: 0.3686 - accuracy: 0.8671 - val_loss: 0.4642 - val_accuracy: 0.8428 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "29688/29688 [==============================] - 396s 13ms/step - loss: 0.3676 - accuracy: 0.8675 - val_loss: 0.4638 - val_accuracy: 0.8434 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "29688/29688 [==============================] - 386s 13ms/step - loss: 0.3665 - accuracy: 0.8678 - val_loss: 0.4605 - val_accuracy: 0.8461 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "29688/29688 [==============================] - 391s 13ms/step - loss: 0.3658 - accuracy: 0.8678 - val_loss: 0.4661 - val_accuracy: 0.8439 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "29688/29688 [==============================] - 390s 13ms/step - loss: 0.3654 - accuracy: 0.8682 - val_loss: 0.4612 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "29688/29688 [==============================] - 393s 13ms/step - loss: 0.3638 - accuracy: 0.8687 - val_loss: 0.4666 - val_accuracy: 0.8430 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "29688/29688 [==============================] - 388s 13ms/step - loss: 0.3635 - accuracy: 0.8690 - val_loss: 0.4611 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "29688/29688 [==============================] - 392s 13ms/step - loss: 0.3615 - accuracy: 0.8698 - val_loss: 0.4747 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "29688/29688 [==============================] - 391s 13ms/step - loss: 0.3615 - accuracy: 0.8696 - val_loss: 0.4679 - val_accuracy: 0.8416 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "29688/29688 [==============================] - 399s 13ms/step - loss: 0.3598 - accuracy: 0.8704 - val_loss: 0.4605 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "29688/29688 [==============================] - 395s 13ms/step - loss: 0.3601 - accuracy: 0.8701 - val_loss: 0.4632 - val_accuracy: 0.8445 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "29688/29688 [==============================] - 388s 13ms/step - loss: 0.3591 - accuracy: 0.8704 - val_loss: 0.4629 - val_accuracy: 0.8445 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "29688/29688 [==============================] - 384s 13ms/step - loss: 0.3583 - accuracy: 0.8706 - val_loss: 0.4653 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "29688/29688 [==============================] - 380s 13ms/step - loss: 0.3575 - accuracy: 0.8708 - val_loss: 0.4679 - val_accuracy: 0.8431 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "29688/29688 [==============================] - 381s 13ms/step - loss: 0.3561 - accuracy: 0.8712 - val_loss: 0.4673 - val_accuracy: 0.8441 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "29688/29688 [==============================] - 386s 13ms/step - loss: 0.3560 - accuracy: 0.8712 - val_loss: 0.4737 - val_accuracy: 0.8420 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "29688/29688 [==============================] - 381s 13ms/step - loss: 0.3549 - accuracy: 0.8719 - val_loss: 0.4679 - val_accuracy: 0.8441 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "29688/29688 [==============================] - 382s 13ms/step - loss: 0.3543 - accuracy: 0.8720 - val_loss: 0.4633 - val_accuracy: 0.8437 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "29688/29688 [==============================] - 380s 13ms/step - loss: 0.3533 - accuracy: 0.8720 - val_loss: 0.4646 - val_accuracy: 0.8438 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "29688/29688 [==============================] - 387s 13ms/step - loss: 0.3525 - accuracy: 0.8728 - val_loss: 0.4755 - val_accuracy: 0.8426 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "29688/29688 [==============================] - 381s 13ms/step - loss: 0.3520 - accuracy: 0.8728 - val_loss: 0.4821 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "29688/29688 [==============================] - 382s 13ms/step - loss: 0.3518 - accuracy: 0.8725 - val_loss: 0.4706 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "29688/29688 [==============================] - 382s 13ms/step - loss: 0.3505 - accuracy: 0.8731 - val_loss: 0.4618 - val_accuracy: 0.8456 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "29688/29688 [==============================] - 382s 13ms/step - loss: 0.3495 - accuracy: 0.8733 - val_loss: 0.4666 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "29688/29688 [==============================] - 386s 13ms/step - loss: 0.3491 - accuracy: 0.8735 - val_loss: 0.4691 - val_accuracy: 0.8427 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "29688/29688 [==============================] - 381s 13ms/step - loss: 0.3489 - accuracy: 0.8737 - val_loss: 0.4686 - val_accuracy: 0.8455 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "29688/29688 [==============================] - 381s 13ms/step - loss: 0.3485 - accuracy: 0.8737 - val_loss: 0.4663 - val_accuracy: 0.8440 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "29688/29688 [==============================] - 382s 13ms/step - loss: 0.3472 - accuracy: 0.8741 - val_loss: 0.4666 - val_accuracy: 0.8457 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "29688/29688 [==============================] - 382s 13ms/step - loss: 0.3470 - accuracy: 0.8743 - val_loss: 0.4650 - val_accuracy: 0.8443 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "29688/29688 [==============================] - 388s 13ms/step - loss: 0.3457 - accuracy: 0.8754 - val_loss: 0.4675 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "29688/29688 [==============================] - 383s 13ms/step - loss: 0.3451 - accuracy: 0.8751 - val_loss: 0.4678 - val_accuracy: 0.8437 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "29688/29688 [==============================] - 381s 13ms/step - loss: 0.3447 - accuracy: 0.8755 - val_loss: 0.4660 - val_accuracy: 0.8463 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "29688/29688 [==============================] - 374s 13ms/step - loss: 0.3447 - accuracy: 0.8751 - val_loss: 0.4809 - val_accuracy: 0.8419 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "29688/29688 [==============================] - 380s 13ms/step - loss: 0.3438 - accuracy: 0.8756 - val_loss: 0.4791 - val_accuracy: 0.8419 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "29688/29688 [==============================] - 374s 13ms/step - loss: 0.3431 - accuracy: 0.8758 - val_loss: 0.4656 - val_accuracy: 0.8446 - lr: 0.0010\n",
      "save failed\n"
     ]
    }
   ],
   "source": [
    "clf = MLSTMFCNWithValidation(\n",
    "    n_epochs=200,\n",
    "    attention=False,\n",
    "    batch_size= 32, \n",
    "    # dilation_rate= 2, \n",
    "    filter_sizes= (64, 128, 64),\n",
    "    kernel_sizes= (5, 3, 1),\n",
    "    lstm_size= 3,\n",
    "    callbacks=callbacks_,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(X_train.transpose().shape)\n",
    "print(y_train.transpose().shape)\n",
    "print(X_val.transpose().shape)\n",
    "print(y_val.transpose().shape)\n",
    "\n",
    "clf.fit(X_train, y_train, X_val, y_val, use_dimension_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6213f87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3, 46)\n",
      "[[[157. 175. 177. ... 293. 300.  90.]\n",
      "  [ 90.  93.  88. ...  44.  43.  75.]\n",
      "  [ 75.  77.  72. ...  51.  50.  50.]]\n",
      "\n",
      " [[241. 221. 246. ... 266. 263. 262.]\n",
      "  [ 96.  99.  89. ...  66.  59.  60.]\n",
      "  [ 76.  73.  80. ...  67.  67.  60.]]\n",
      "\n",
      " [[190. 178. 188. ... 214. 176.  73.]\n",
      "  [ 73.  73.  76. ...  57.  48.  61.]\n",
      "  [ 61.  58.  56. ...  44.  51.  51.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[106. 106. 140. ... 118. 101.  70.]\n",
      "  [ 70.  70.  90. ...  78.  64.  59.]\n",
      "  [ 59.  59.  72. ...  63.  53.  53.]]\n",
      "\n",
      " [[175. 175. 208. ... 179. 146. 175.]\n",
      "  [ 93.  93. 102. ... 112.  77.  68.]\n",
      "  [ 81.  81.  91. ...  95.  68.  69.]]\n",
      "\n",
      " [[208. 209. 211. ... 328. 283.  67.]\n",
      "  [ 67.  56.  68. ...  51.  53.  55.]\n",
      "  [ 55.  54.  58. ...  66.  68.  68.]]]\n",
      "(20000, 3, 46)\n",
      "625/625 [==============================] - 4s 4ms/step\n",
      "Saved file: baseline_mlstm_submission_multivariate_new_params_phase2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTED</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PREDICTED\n",
       "ID           \n",
       "0           1\n",
       "1           9\n",
       "2           9\n",
       "3          18\n",
       "4           3"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_TEST = \"./dataset/SITS-test-data-phase2-nolabel.csv.gz\"\n",
    "\n",
    "X_test, _ = read_data_sktime(DATA_TEST, univariate=use_univariate)\n",
    "# X_test, _ = read_data_sktime(DATA_TEST, univariate=True)\n",
    "print(X_test)\n",
    "\n",
    "# Make a prediction\n",
    "predictions = clf.predict(X_test, use_dimension_shuffle=False)\n",
    "\n",
    "\n",
    "# Create a submission file for kaggle\n",
    "submission = pd.DataFrame({'PREDICTED': predictions})\n",
    "submission.index.name=\"ID\"\n",
    "\n",
    "filename = 'baseline_mlstm_submission_multivariate_new_params_phase2.csv'\n",
    "submission.to_csv(filename,index=True)\n",
    "print('Saved file: ' + filename)\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5130e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d762ffc7d2f958e0963c75da0d959adf181f4ac62524ed3e80179df28269f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
