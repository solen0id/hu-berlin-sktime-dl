{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ef176be",
   "metadata": {},
   "source": [
    "# Train sktime-dl MLSTM-FCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4365e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Only print warnings, ignore info and error \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # Disable GPU\n",
    "\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' \n",
    "# import tensorflow as tf\n",
    "# tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from sktime.classification.deep_learning.mlstmfcn import MLSTMFCNClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf079b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "(850000, 4, 46)\n",
      "(850000,)\n",
      "\n",
      "Validation data:\n",
      "(150000, 4, 46)\n",
      "(150000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can use a larger subset, if you like, there are:\n",
    "# - SITS-train-phase2-subset-1000000.csv.gz\n",
    "# - SITS-train-phase2-subset-100000.csv.gz\n",
    "# - SITS-train-phase2-subset-10000.csv.gz\n",
    "DATA_TRAIN = \"./dataset/SITS-train-phase2-subset-1000000.csv.gz\"\n",
    "use_univariate = False\n",
    "indices_f = [\n",
    "    lambda n,r,g: (n - r) / (n + r),    # vegetation index\n",
    "    #lambda n,r,g: (n - g) / (n + g),    # water index\n",
    "    #lambda n,r,g: (n * r) / (g ** 2),   # chlorophyll index\n",
    "    #lambda n,r,g: np.sqrt(n ** 2 + r ** 2 + g ** 2) # brightness\n",
    "]\n",
    "\n",
    "# Set univariate=False, if you use a classifier with multivariate capabilities\n",
    "def read_data_sktime(DATA, univariate=False, indices_f=[]):\n",
    "    data = pd.read_csv(DATA, delimiter=\",\" , \n",
    "                       na_values=['?'], dtype='float', \n",
    "                       index_col=\"id\", compression='gzip')\n",
    "\n",
    "    # Fill NaN values\n",
    "    # We use the most basic way with bfill and ffill to carry on the last values\n",
    "    data.fillna(method='bfill', inplace=True, axis=1)\n",
    "    data.fillna(method='ffill', inplace=True, axis=1)\n",
    "\n",
    "    # Extract Data and Labels\n",
    "    X = data.iloc[:,1:]\n",
    "    y = data.iloc[:,0].astype(int)\n",
    "\n",
    "    # Extract value groups\n",
    "    s = X.shape[1]//3\n",
    "    nir = X.iloc[:,0:s].to_numpy()\n",
    "    red = X.iloc[:,s:2*s].to_numpy()\n",
    "    green = X.iloc[:,2*s:3*s].to_numpy()\n",
    "    X = [X]\n",
    "\n",
    "    # Calculate indices\n",
    "    for i in indices_f:\n",
    "        X.append(i(nir, red, green))\n",
    "\n",
    "    X = np.concatenate(X, axis=1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if univariate:\n",
    "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    else:\n",
    "        X = X.reshape(X.shape[0], 3 + len(indices_f), X.shape[1] // (3 + len(indices_f)))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = read_data_sktime(DATA_TRAIN, univariate=use_univariate, indices_f=indices_f)\n",
    "\n",
    "for (train_ix, test_ix)  in StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42).split(X, y):\n",
    "    X_train, y_train = X[train_ix], y[train_ix]\n",
    "    X_val, y_val = X[test_ix], y[test_ix]\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Validation data:\")\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b861481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.7, patience=10, min_lr=0.0001)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "tensorboard = callbacks.TensorBoard(log_dir=\"./tensorboard/phase_2_mlstm_full_dataset_tuned_and_fixed_multivariate_with_dilation\", histogram_freq=1)\n",
    "# model_save = callbacks.ModelCheckpoint('best_model_exploring.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "callbacks_ = [early_stopping, reduce_lr, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf156fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLSTMFCNWithValidation(MLSTMFCNClassifier):\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None, **kwargs):\n",
    "        self.reset()\n",
    "\n",
    "        start = int(round(time.time() * 1000))\n",
    "        # convenience conversions to allow user flexibility:\n",
    "        # if X is 2D array, convert to 3D, if y is Series, convert to numpy\n",
    "        X, y = self._internal_convert(X, y)\n",
    "        X_metadata = self._check_classifier_input(X, y)\n",
    "        missing = X_metadata[\"has_nans\"]\n",
    "        multivariate = not X_metadata[\"is_univariate\"]\n",
    "        unequal = not X_metadata[\"is_equal_length\"]\n",
    "        self._X_metadata = X_metadata\n",
    "\n",
    "        # Check this classifier can handle characteristics\n",
    "        self._check_capabilities(missing, multivariate, unequal)\n",
    "\n",
    "        # remember class labels\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = self.classes_.shape[0]\n",
    "        self._class_dictionary = {}\n",
    "        for index, class_val in enumerate(self.classes_):\n",
    "            self._class_dictionary[class_val] = index\n",
    "\n",
    "        # escape early and do not fit if only one class label has been seen\n",
    "        #   in this case, we later predict the single class label seen\n",
    "        if len(self.classes_) == 1:\n",
    "            self.fit_time_ = int(round(time.time() * 1000)) - start\n",
    "            self._is_fitted = True\n",
    "            return self\n",
    "\n",
    "        # Convert data as dictated by the classifier tags\n",
    "        X = self._convert_X(X)\n",
    "        multithread = self.get_tag(\"capability:multithreading\")\n",
    "        if multithread:\n",
    "            try:\n",
    "                self._threads_to_use = check_n_jobs(self.n_jobs)\n",
    "            except NameError:\n",
    "                raise AttributeError(\n",
    "                    \"self.n_jobs must be set if capability:multithreading is True\"\n",
    "                )\n",
    "\n",
    "        # pass coerced and checked data to inner _fit\n",
    "        self._fit(X, y, X_val, y_val, **kwargs)\n",
    "        self.fit_time_ = int(round(time.time() * 1000)) - start\n",
    "\n",
    "        # this should happen last\n",
    "        self._is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def _fit(self, X, y, X_val=None, y_val=None, **kwargs):\n",
    "        from sklearn.utils.validation import check_random_state\n",
    "        \n",
    "        self.random_state = check_random_state(self.random_state)\n",
    "        y_onehot = self.convert_y_to_keras(y)\n",
    "        \n",
    "        if y_val is not None:\n",
    "            y_val = self.label_encoder.transform(y_val)\n",
    "            y_val = y_val.reshape(-1, 1)\n",
    "            y_val = self.onehot_encoder.transform(y_val)\n",
    "\n",
    "        # Transpose to conform to Keras input style.\n",
    "        X = X.transpose(0, 2, 1)\n",
    "        \n",
    "        if X_val is not None:\n",
    "             X_val = X_val.transpose(0, 2, 1)\n",
    "             \n",
    "        validation_data = (X_val, y_val) if X_val is not None and y_val is not None else None\n",
    "\n",
    "        # ignore the number of instances, X.shape[0],\n",
    "        # just want the shape of each instance\n",
    "        self.input_shape = X.shape[1:]\n",
    "\n",
    "        self.model_ = self.build_model(self.input_shape, self.n_classes_)\n",
    "\n",
    "        if self.verbose:\n",
    "            self.model_.summary()\n",
    "\n",
    "        self.history = self.model_.fit(\n",
    "            X,\n",
    "            y_onehot,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.n_epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_data=validation_data,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self._is_fitted = True\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96bbf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 46, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 46, 64)       1344        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 46, 64)      256         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 46, 64)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 64)          0           ['activation[0][0]']             \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 64)        0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 4)         256         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 64)        256         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 46, 64)       0           ['activation[0][0]',             \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 46, 128)      24704       ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 46, 128)     512         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 46, 128)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['activation_1[0][0]']           \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 128)       0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 8)         1024        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1, 128)       1024        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 46, 128)      0           ['activation_1[0][0]',           \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 46, 64)       8256        ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 4, 46)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 46, 64)      256         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 3)            600         ['permute[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 46, 64)       0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 3)            0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 64)          0           ['activation_2[0][0]']           \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 67)           0           ['dropout[0][0]',                \n",
      "                                                                  'global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 24)           1632        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,120\n",
      "Trainable params: 39,608\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "26563/26563 [==============================] - 233s 9ms/step - loss: 0.8197 - accuracy: 0.7145 - val_loss: 0.7970 - val_accuracy: 0.7197 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "26563/26563 [==============================] - 237s 9ms/step - loss: 0.6981 - accuracy: 0.7558 - val_loss: 0.7269 - val_accuracy: 0.7472 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "26563/26563 [==============================] - 240s 9ms/step - loss: 0.6622 - accuracy: 0.7683 - val_loss: 0.6776 - val_accuracy: 0.7632 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "26563/26563 [==============================] - 251s 9ms/step - loss: 0.6410 - accuracy: 0.7758 - val_loss: 0.6407 - val_accuracy: 0.7745 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "26563/26563 [==============================] - 258s 10ms/step - loss: 0.6256 - accuracy: 0.7807 - val_loss: 0.6386 - val_accuracy: 0.7764 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "26563/26563 [==============================] - 263s 10ms/step - loss: 0.6139 - accuracy: 0.7850 - val_loss: 0.6433 - val_accuracy: 0.7745 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "26563/26563 [==============================] - 267s 10ms/step - loss: 0.6045 - accuracy: 0.7883 - val_loss: 0.7450 - val_accuracy: 0.7367 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "26563/26563 [==============================] - 275s 10ms/step - loss: 0.5970 - accuracy: 0.7910 - val_loss: 0.6283 - val_accuracy: 0.7789 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "26563/26563 [==============================] - 283s 11ms/step - loss: 0.5904 - accuracy: 0.7935 - val_loss: 0.6216 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "26563/26563 [==============================] - 291s 11ms/step - loss: 0.5841 - accuracy: 0.7957 - val_loss: 0.6103 - val_accuracy: 0.7869 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "26563/26563 [==============================] - 298s 11ms/step - loss: 0.5795 - accuracy: 0.7977 - val_loss: 0.6043 - val_accuracy: 0.7887 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "26563/26563 [==============================] - 306s 12ms/step - loss: 0.5755 - accuracy: 0.7990 - val_loss: 0.6118 - val_accuracy: 0.7854 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "26563/26563 [==============================] - 315s 12ms/step - loss: 0.5717 - accuracy: 0.8001 - val_loss: 0.6050 - val_accuracy: 0.7860 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "26563/26563 [==============================] - 325s 12ms/step - loss: 0.5683 - accuracy: 0.8017 - val_loss: 0.5863 - val_accuracy: 0.7956 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "26563/26563 [==============================] - 336s 13ms/step - loss: 0.5652 - accuracy: 0.8023 - val_loss: 0.5905 - val_accuracy: 0.7951 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "26563/26563 [==============================] - 345s 13ms/step - loss: 0.5621 - accuracy: 0.8035 - val_loss: 0.5794 - val_accuracy: 0.7962 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "26563/26563 [==============================] - 357s 13ms/step - loss: 0.5595 - accuracy: 0.8045 - val_loss: 0.5776 - val_accuracy: 0.7976 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "26563/26563 [==============================] - 370s 14ms/step - loss: 0.5575 - accuracy: 0.8047 - val_loss: 0.6114 - val_accuracy: 0.7897 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "26563/26563 [==============================] - 378s 14ms/step - loss: 0.5549 - accuracy: 0.8064 - val_loss: 0.5762 - val_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "26563/26563 [==============================] - 389s 15ms/step - loss: 0.5532 - accuracy: 0.8066 - val_loss: 0.5872 - val_accuracy: 0.7925 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "26563/26563 [==============================] - 402s 15ms/step - loss: 0.5508 - accuracy: 0.8073 - val_loss: 0.5758 - val_accuracy: 0.7980 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "26563/26563 [==============================] - 426s 16ms/step - loss: 0.5495 - accuracy: 0.8077 - val_loss: 0.5740 - val_accuracy: 0.7993 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "26563/26563 [==============================] - 515s 19ms/step - loss: 0.5471 - accuracy: 0.8089 - val_loss: 0.5808 - val_accuracy: 0.7971 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "26563/26563 [==============================] - 534s 20ms/step - loss: 0.5461 - accuracy: 0.8087 - val_loss: 0.5784 - val_accuracy: 0.7985 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "26563/26563 [==============================] - 560s 21ms/step - loss: 0.5442 - accuracy: 0.8098 - val_loss: 0.5837 - val_accuracy: 0.7965 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "26563/26563 [==============================] - 584s 22ms/step - loss: 0.5431 - accuracy: 0.8099 - val_loss: 0.5696 - val_accuracy: 0.8012 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "26563/26563 [==============================] - 611s 23ms/step - loss: 0.5417 - accuracy: 0.8105 - val_loss: 0.5982 - val_accuracy: 0.7932 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "26563/26563 [==============================] - 633s 24ms/step - loss: 0.5403 - accuracy: 0.8108 - val_loss: 0.5662 - val_accuracy: 0.8019 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "26563/26563 [==============================] - 652s 25ms/step - loss: 0.5391 - accuracy: 0.8114 - val_loss: 0.5723 - val_accuracy: 0.7995 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "26563/26563 [==============================] - 670s 25ms/step - loss: 0.5375 - accuracy: 0.8116 - val_loss: 0.5823 - val_accuracy: 0.7966 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "26563/26563 [==============================] - 688s 26ms/step - loss: 0.5366 - accuracy: 0.8120 - val_loss: 0.5617 - val_accuracy: 0.8024 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "26563/26563 [==============================] - 712s 27ms/step - loss: 0.5356 - accuracy: 0.8128 - val_loss: 0.5793 - val_accuracy: 0.7984 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "26563/26563 [==============================] - 740s 28ms/step - loss: 0.5341 - accuracy: 0.8126 - val_loss: 0.5572 - val_accuracy: 0.8052 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "26563/26563 [==============================] - 767s 29ms/step - loss: 0.5330 - accuracy: 0.8132 - val_loss: 0.5808 - val_accuracy: 0.7991 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "26563/26563 [==============================] - 788s 30ms/step - loss: 0.5327 - accuracy: 0.8135 - val_loss: 0.5647 - val_accuracy: 0.8023 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "26563/26563 [==============================] - 807s 30ms/step - loss: 0.5312 - accuracy: 0.8142 - val_loss: 0.5531 - val_accuracy: 0.8063 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "26563/26563 [==============================] - 832s 31ms/step - loss: 0.5303 - accuracy: 0.8144 - val_loss: 0.5596 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "26563/26563 [==============================] - 857s 32ms/step - loss: 0.5294 - accuracy: 0.8145 - val_loss: 0.5577 - val_accuracy: 0.8036 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "26563/26563 [==============================] - 895s 34ms/step - loss: 0.5286 - accuracy: 0.8148 - val_loss: 0.5483 - val_accuracy: 0.8085 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "26563/26563 [==============================] - 904s 34ms/step - loss: 0.5281 - accuracy: 0.8151 - val_loss: 0.5674 - val_accuracy: 0.8001 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "26563/26563 [==============================] - 935s 35ms/step - loss: 0.5273 - accuracy: 0.8156 - val_loss: 0.5518 - val_accuracy: 0.8077 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "26563/26563 [==============================] - 956s 36ms/step - loss: 0.5268 - accuracy: 0.8157 - val_loss: 0.5558 - val_accuracy: 0.8053 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "26563/26563 [==============================] - 975s 37ms/step - loss: 0.5256 - accuracy: 0.8158 - val_loss: 0.5574 - val_accuracy: 0.8044 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "26563/26563 [==============================] - 1001s 38ms/step - loss: 0.5249 - accuracy: 0.8163 - val_loss: 0.5461 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "26563/26563 [==============================] - 1021s 38ms/step - loss: 0.5241 - accuracy: 0.8161 - val_loss: 0.5530 - val_accuracy: 0.8075 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "26563/26563 [==============================] - 1053s 40ms/step - loss: 0.5230 - accuracy: 0.8168 - val_loss: 0.5566 - val_accuracy: 0.8047 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "26563/26563 [==============================] - 1079s 41ms/step - loss: 0.5231 - accuracy: 0.8169 - val_loss: 0.5684 - val_accuracy: 0.7986 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "26563/26563 [==============================] - 1111s 42ms/step - loss: 0.5224 - accuracy: 0.8171 - val_loss: 0.5553 - val_accuracy: 0.8064 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "26563/26563 [==============================] - 1113s 42ms/step - loss: 0.5215 - accuracy: 0.8171 - val_loss: 0.5454 - val_accuracy: 0.8090 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "26563/26563 [==============================] - 1152s 43ms/step - loss: 0.5211 - accuracy: 0.8173 - val_loss: 0.5473 - val_accuracy: 0.8090 - lr: 0.0010\n",
      "625/625 [==============================] - 8s 12ms/step\n",
      "Saved file: mlstm_submission_1M_indices.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTED</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PREDICTED\n",
       "ID           \n",
       "0           1\n",
       "1           9\n",
       "2           2\n",
       "3          18\n",
       "4           3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLSTMFCNWithValidation(\n",
    "    n_epochs=50,\n",
    "    attention=False,\n",
    "    batch_size= 32, \n",
    "    dilation_rate= 2, \n",
    "    filter_sizes= (64, 128, 64),\n",
    "    kernel_sizes= (5, 3, 1),\n",
    "    lstm_size= 3,\n",
    "    callbacks=callbacks_,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST = \"./dataset/SITS-test-data-phase2-nolabel.csv.gz\"\n",
    "\n",
    "X_test, _ = read_data_sktime(DATA_TEST, univariate=use_univariate, indices_f=indices_f)\n",
    "\n",
    "# Make a prediction\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Create a submission file for kaggle\n",
    "submission = pd.DataFrame({'PREDICTED': predictions})\n",
    "submission.index.name=\"ID\"\n",
    "\n",
    "filename = 'predictions/mlstm_submission_1M_indices.csv'\n",
    "submission.to_csv(filename,index=True)\n",
    "print('Saved file: ' + filename)\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
